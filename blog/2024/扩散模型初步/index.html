<!DOCTYPE html> <html lang="cn"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 扩散模型初步 | Li Fancheng </title> <meta name="author" content="Li Fancheng"> <meta name="description" content="扩散模型入门，包括DDPM和SLDM"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/logo.png?cb3bc9f6d3fdd652caf64b904e3f65a3"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://lfcdepression.github.io/blog/2024/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%AD%A5/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Li</span> Fancheng </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Notes </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">扩散模型初步</h1> <p class="post-meta"> Created in October 02, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/diffusion-model"> <i class="fa-solid fa-hashtag fa-sm"></i> diffusion-model</a>   ·   <a href="/blog/category/machine-learning"> <i class="fa-solid fa-tag fa-sm"></i> machine-learning</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <h2 id="目录">目录</h2> <ul> <li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li> <li> <a href="#1-%E8%83%8C%E6%99%AF">1 背景</a> <ul> <li><a href="#11-elbo%E8%AF%81%E6%8D%AE%E4%B8%8B%E7%95%8C">1.1 ELBO证据下界</a></li> <li><a href="#12-variational-autoencoders">1.2 Variational Autoencoders</a></li> </ul> </li> <li> <a href="#2-%E5%8F%98%E5%88%86%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B">2 变分扩散模型</a> <ul> <li><a href="#21-%E6%A8%A1%E5%9E%8B%E6%A1%86%E6%9E%B6">2.1 模型框架</a></li> <li><a href="#22-learning-diffusion-noise-parameters">2.2 Learning Diffusion Noise Parameters</a></li> <li><a href="#23-three-equivalent-interpretations">2.3 Three Equivalent Interpretations</a></li> </ul> </li> <li><a href="#3-score-based-generative-models">3 Score-based Generative Models</a></li> <li> <a href="#4-guidence">4 Guidence</a> <ul> <li><a href="#41-classifier-guidance">4.1 Classifier Guidance</a></li> <li><a href="#42-classifier-free-guidance">4.2 Classifier-Free Guidance</a></li> </ul> </li> </ul> <h2 id="1-背景">1 背景</h2> <h3 id="11-elbo证据下界">1.1 ELBO证据下界</h3> <p>可以将潜在变量和观测变量视为一个联合分布 $p(\boldsymbol{x,z})$ ，一个基础的思路是使用“似然法”，是所有观测 $\boldsymbol{x}$ 的似然 $p(\boldsymbol{x})$ 最大化，有两种方法可以得到似然：</p> \[p(\boldsymbol{x})=\int p(\boldsymbol{x},\boldsymbol{z})\mathrm{d}\boldsymbol{z}\] <p>或者可以使用条件概率：</p> \[p(\boldsymbol{x})=\frac{p(\boldsymbol{x},\boldsymbol{z})}{p(\boldsymbol{z}\vert\boldsymbol{x})}\] <p>这两个式子在计算上都有很大的困难，第一个式子的问题在于需要对所有的$\boldsymbol{z}$进行积分，第二个式子的难度在于需要知道$p(\boldsymbol{z}\vert\boldsymbol{x})$，但是利用这两个公式我们可以得到ELBO，即证据下界。证据是观测数据的对数似然，最大化ELBO时，即完美情况下，ELBO与证据相等。</p> \[\log p(\boldsymbol{x})\geq\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\bigg[\log\frac{p(\boldsymbol{x},\boldsymbol{z})}{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\bigg]\] <p>这里，$q_\phi(\boldsymbol{z}\vert\boldsymbol{x})$是优化参数为$\phi$的变分近似分布。是一个可参数化的模型，用来估计给定观测值$\boldsymbol{x}$在潜在变量$\boldsymbol{z}$上的真实分布。</p> \[\begin{aligned} \operatorname{log}p(\boldsymbol{x})&amp; =\int q_\phi(\boldsymbol{z}\vert\boldsymbol{x})\log p(\boldsymbol{x})\mathrm{d}\boldsymbol{z} \\ &amp;=\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\begin{bmatrix}\log p(\boldsymbol{x})\end{bmatrix} \\ &amp;=\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x},\boldsymbol{z})q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}{p(\boldsymbol{z}\vert\boldsymbol{x})q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\right] \\ &amp;=\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\Bigg[\log\frac{p(\boldsymbol{x},\boldsymbol{z})}{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\Bigg]-\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\Bigg[\log\frac{p(\boldsymbol{z}\vert\boldsymbol{x})}{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\Bigg] \\ &amp;=\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\Bigg[\log\frac{p(\boldsymbol{x},\boldsymbol{z})}{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\Bigg]+D_{KL}(q_\phi(\boldsymbol{z}\vert\boldsymbol{x})\Vert p(\boldsymbol{z}\vert\boldsymbol{x})) \end{aligned}\] <p>即证据等于证据下界ELBO与近似后验分布$q_{\phi}(\boldsymbol{z}\vert \boldsymbol{x})$、真实后验分布$p(\boldsymbol{z}\vert\boldsymbol{x})$的KL散度之和。</p> <p>在引入潜变量之后，我们的目标是学习描述观测数据的潜在结构，即通过最小化KL散度优化变分后验分布的参数使其与真实后验分布相同。但因为无法直接得到真实后验，因此无法直接进行优化。但因为数据似然（证据）是从联合分布中求出所有的潜在变量的边缘分布得到，与$\phi$无关，因此是相对于$\phi$的常数。即ELBO与KL散度之和为常数，因此对于$\phi$的ELBO最大化，一定会得到KL散度的最小化，因此ELBO可以作为模型建立的替代目标被最大化。</p> <h3 id="12-variational-autoencoders">1.2 Variational Autoencoders</h3> <p>在VAE中使用变分直接最大化ELBO，在参数$\phi$参数化的后验分布的潜空间中搜素最优解，被称为自编码器。</p> \[\begin{aligned} &amp;\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\left[\log\frac{p(\boldsymbol{x},\boldsymbol{z})}{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\right] \\ =&amp;\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\left[\log\frac{p_\theta(\boldsymbol{x}\vert\boldsymbol{z})p(\boldsymbol{z})}{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\right] \\ =&amp;\underbrace{\mathbb{E}_{q_\phi(\boldsymbol{z}\vert\boldsymbol{x})}\left[\log p_\theta(\boldsymbol{x}\vert\boldsymbol{z})\right]}_{\text{重建项}}-\underbrace{D_{KL}(q_\phi(\boldsymbol{z}\vert\boldsymbol{x})\parallel p(\boldsymbol{z}))}_{\text{先验匹配项}} \end{aligned}\] <p>这种情况下，学习一个编码器$q_\phi(\boldsymbol{z}\vert\boldsymbol{x})$，将输入转换为潜在变量上的分布，同时学习一个函数$p_\theta(\boldsymbol{x}\vert\boldsymbol{z})$将给定潜在变量转换为观测值，即解码器。</p> <p>第一项是解码器重建似然性，第二项是变分分布和先验分布在潜在变量空间上的相似度，最大化ELBO相当于最大化第一项，并最小化第二项。</p> <p>VAE的一个特点是联合优化两个参数$\phi$和$\theta$，先验通常被选择为标准高斯分布：</p> \[\begin{aligned}q_\phi(\boldsymbol{z}\vert\boldsymbol{x})&amp;=\mathcal{N}(\boldsymbol{z};\boldsymbol{\mu}_\phi(\boldsymbol{x}),\boldsymbol{\sigma}_\phi(\boldsymbol{x})\boldsymbol{I})\\p(\boldsymbol{z})&amp;=\mathcal{N}(\boldsymbol{z};0,\boldsymbol{I})\end{aligned}\] <p>由此，ELBO的KL散度可以被解析计算，重构项（第一项）可以使用Monte Carlo方法近似：</p> \[\begin{aligned}&amp;\arg\max_{\phi,\theta}\mathbb{E}_{q_{\phi}(\boldsymbol{z}\vert\boldsymbol{x})}\left\lfloor\log p_{\theta}(\boldsymbol{x}\vert\boldsymbol{z})\right\rfloor-D_{KL}(q_{\phi}(\boldsymbol{z}\vert\boldsymbol{x})\parallel p(\boldsymbol{z})) \\ \approx&amp;\arg\max_{\phi,\theta}\frac{1}{I}\sum_{I}^{L}\log p_{\theta}(\boldsymbol{x} \vert \boldsymbol{z}^{(l)})-D_{KL}(q_{\phi}(\boldsymbol{z} \vert \boldsymbol{x})\\vert p(\boldsymbol{z}))\end{aligned}\] <p>我们从每个数据集的观察值使用$q_\phi(\boldsymbol{z}\vert\boldsymbol{x})$对潜变量进行采样，但我们计算损失的每个值都是随机采样的，会导致不可导。使用重参数化可以解决这个问题，重参数化将一个随机变量写为一个噪声变量的确定的函数，由此可以使用梯度下降优化非随机项，例如正态分布中采样的样本满足：</p> \[\boldsymbol{x}=\boldsymbol{\mu}+\boldsymbol{\sigma}\boldsymbol{\epsilon}\quad\mathrm{with}\quad \boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{\epsilon};0,\boldsymbol{I})\] <p>在VAE中，每个$\boldsymbol{z}$都被计算为输入$\boldsymbol{x}$和噪声变量$\boldsymbol{\epsilon}$的确定性函数：</p> \[\boldsymbol{z}=\boldsymbol{\mu}_\phi(\boldsymbol{x})+\boldsymbol{\sigma}_\phi(\boldsymbol{x})\odot\boldsymbol{\epsilon} \quad with\quad \boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{\epsilon};0,\boldsymbol{I})\] <p>其中$\odot$表示逐个元素相乘，在重参数化的情况下，梯度可以根据$\phi$计算，由此优化$\boldsymbol{\mu}<em>\phi$和 $\boldsymbol{\sigma}</em>\phi$，VAE利用重参数化和Monte Carlo来优化ELBO。</p> <p>训练完成之后，可以直接从潜空间采样，并将其输入解码器生成。潜变量维度小于样本维度时，会有比较好的结果。</p> <h2 id="2-变分扩散模型">2 变分扩散模型</h2> <h3 id="21-模型框架">2.1 模型框架</h3> <p>变分扩散模型（Variational Diffusion Model，VDM）最简单的理解是一个具有三个关键限制的马尔可夫层级变分自编码器：</p> <ul> <li>潜在维度与数据维度完全相等。</li> <li>每个时刻潜在编码器的结构不是学习得来的，而是预定义为线性高斯模型。</li> <li>潜在编码器的高斯参数随时间变化，使得最终时刻的潜在分布是标准高斯分布。</li> </ul> <p>根据第一个限制，我们可以得到将真实数据样本和潜变量多都表示为$\boldsymbol{x}_{t}$，其中$t=0$时表示真实数据，$t\in[1,T]$，表示相应的具有由$t$索引的层级的潜变量。</p> \[q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)=\prod_{t=1}^Tq(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1})\] <p>根据第二个假设，编码器中每个潜变量分布是围绕前一个潜变量的高斯分布，编码器不会被学习，而是被固定，均值和标准差可以事先设置为超参数或者学习的参数：</p> \[q(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1})=\mathcal{N}(\boldsymbol{x}_t;\sqrt{\alpha_t}\boldsymbol{x}_{t-1},(1-\alpha_t)\boldsymbol{I})\] <p>根据第三个假设，最终潜变量分布是一个标准高斯分布：</p> \[p(\boldsymbol{x}_{0:T})=p(\boldsymbol{x}_T)\prod_{t=1}^Tp_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t)\quad \text{where} \quad p(\boldsymbol{x}_T)=\mathcal{N}(\boldsymbol{x}_T;0,\boldsymbol{I})\] <p>编码器分布$q$不再由$\phi$参数化，因此我们只需要关心参数$\theta$，来学习反向过程的条件概率。</p> <p>使用最大化证据下界ELBO来进行优化：</p> \[\begin{aligned}\log p(\boldsymbol{x})&amp;=\log\int\frac{p(\boldsymbol{x}_{0:T})q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_{0})}{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_{0})}\mathrm{d}\boldsymbol{x}_{1:T}\\&amp;=\log\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_{0})}\left[\frac{p(\boldsymbol{x}_{0:T})}{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_{0})}\right]\\&amp;\geq\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_{0})}\left[\log\frac{p(\boldsymbol{x}_{0:T})}{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_{0})}\right]\end{aligned}\] <p>更进一步我们可以得到：</p> \[\begin{aligned} &amp;\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\bigg\lfloor\log\frac{p(\boldsymbol{x}_{0:T})}{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\bigg\rfloor \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\Bigg[\log\frac{p(\boldsymbol{x}_T)\prod_{t=1}^Tp_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t)}{\prod_{t=1}^Tq(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1})}\Bigg] \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log\frac{p(\boldsymbol{x}_T)p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)\prod_{t=1}^{T-1}p_\theta(\boldsymbol{x}_t\vert\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_T\vert\boldsymbol{x}_{T-1})\prod_{t=1}^{T-1}q(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1})}\right] \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\Big[\log p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)\Big]+\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\Bigg[\log\frac{p(\boldsymbol{x}_T)}{q(\boldsymbol{x}_T\vert\boldsymbol{x}_{T-1})}\Bigg]\\&amp;+\sum_{t=1}^{T-1}\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\Bigg[\log\frac{p_\theta(\boldsymbol{x}_t\vert\boldsymbol{x}_{t+1})}{q(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1})}\Bigg] \\ &amp;=\underbrace{\mathbb{E}_{q(\boldsymbol{x}_1\vert\boldsymbol{x}_0)}\left[\log p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)\right]}_{\text{重构项}}\\&amp;-\underbrace{\mathbb{E}_{q(\boldsymbol{x}_{T-1}\vert\boldsymbol{x}_0)}\left[D_{KL}(q(\boldsymbol{x}_T\vert\boldsymbol{x}_{T-1})\vert p(\boldsymbol{x}_T))\right]}_{\text{先验匹配项}}\\&amp;-\underbrace{\sum_{t=1}^{T-1}\mathbb{E}_{q(\boldsymbol{x}_{t-1},\boldsymbol{x}_{t+1}\vert\boldsymbol{x}_0)}\left[D_{KL}(q(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1})\vert p_\theta(\boldsymbol{x}_t \vert\boldsymbol{x}_{t+1}))\right]}_{\text{一致性项}} \end{aligned}\] <ul> <li>第一项是重构项，预测了给定第一步潜变量时原始数据的对数概率。</li> <li>第二项是先验匹配项，最终潜变量分布和高斯分布相匹配时，可以被最小化。这一项自然最小化，而不需要进行优化。</li> <li>第三项是一致性项，要求每个中间时间步上，从更多噪声的图像进行去噪处理，从而与更清晰的图像进行加噪处理的结果匹配，即向前和向后的一致性。</li> </ul> <p>现在出现了一个问题：在每一个时间步上都需要训练一次第三项，而为了保证第二项最小化，我们需要足够多的时间步，因此会导致训练时间成本极高。</p> <p>同时，ELBO所有项都可以通过期望计算，因此都可以使用Monte Carlo方法，但实际上我们很难得到最优解，因为一致性项还有一个问题：是对每个时间步骤计算两个随机变量的期望，计算结果的方差高于一个随机变量的项，因此，在求和之后ELBO还可以有较高的方差。</p> <p>因此从计算成本和精度上，我们需要对之前的方法进行进一步的改进。精度的问题涉及模型是否可用，因此我们先解决精度问题，即改成对一个随机变量采样，根据贝叶斯定理我们有：</p> \[q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0)=\frac{q(\boldsymbol{x}_t\vert \boldsymbol{x}_{t-1},\boldsymbol{x}_0)q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_0)}{q(\boldsymbol{x}_t\vert \boldsymbol{x}_0)}\] <p>因此我们可以尝试使用上面这个公式将一致性公式转换为，真实后验和预测后验概率的匹配：</p> \[\begin{aligned} &amp;\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\bigg[\log\frac{p(\boldsymbol{x}_{0:T})}{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\bigg] \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log\frac{p(\boldsymbol{x}_T)p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)\prod_{t=2}^Tp_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t)}{q(\boldsymbol{x}_1\vert\boldsymbol{x}_0)\prod_{t=2}^Tq(\boldsymbol{x}_t\vert\boldsymbol{x}_{t-1},\boldsymbol{x}_0)}\right] \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log\frac{p(\boldsymbol{x}_T)p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)}{q(\boldsymbol{x}_1\vert\boldsymbol{x}_0)}+\log\prod_{t=2}^T\frac{p_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t)}{\frac{q(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t,\boldsymbol{x}_0)q(\boldsymbol{x}_t\vert\boldsymbol{x}_0)}{q(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_0)}}\right] \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log\frac{p(\boldsymbol{x}_T)p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)}{q(\boldsymbol{x}_1\vert\boldsymbol{x}_0)}+\log\frac{q(\boldsymbol{x}_1\vert\boldsymbol{x}_0)}{q(\boldsymbol{x}_T\vert\boldsymbol{x}_0)}\\+\log\prod_{t=2}^T\frac{p_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t)}{q(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t,\boldsymbol{x}_0)}\right] \\ &amp;=\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)\right]+\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log\frac{p(\boldsymbol{x}_T)}{q(\boldsymbol{x}_T\vert\boldsymbol{x}_0)}\right]\\&amp;+\sum_{t=2}^T\mathbb{E}_{q(\boldsymbol{x}_{1:T}\vert\boldsymbol{x}_0)}\left[\log\frac{p_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t)}{q(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t,\boldsymbol{x}_0)}\right] \\ &amp;=\underbrace{\mathbb{E}_{q(\boldsymbol{x}_1\vert\boldsymbol{x}_0)}\left[\log p_\theta(\boldsymbol{x}_0\vert\boldsymbol{x}_1)\right]}_{\text{重构项}} \\ &amp;-\underbrace{D_{KL}(q(\boldsymbol{x}_T\vert\boldsymbol{x}_0)\parallel p(\boldsymbol{x}_T))}_{\text{先验匹配项}} \\ &amp;-\underbrace{\sum_{t=2}^T\mathbb{E}_{q(\boldsymbol{x}_t,\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_0)}\left[D_{KL}(q(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t,\boldsymbol{x}_0)\parallel p_\theta(\boldsymbol{x}_{t-1}\vert\boldsymbol{x}_t))\right]}_{\text{去噪匹配项}} \end{aligned}\] <p>第三项从一致性项变为去噪匹配项，即使预测后验概率与真实后验概率尽可能相同。</p> <p>对于前面的式子，我们已经知道其中一部分，即$q(\boldsymbol{x}<em>t\vert \boldsymbol{x}</em>{t-1},\boldsymbol{x}<em>0)=q(\boldsymbol{x}_t\vert \boldsymbol{x}</em>{t-1})=\mathcal{N}(\boldsymbol{x}<em>t;\sqrt{\alpha_t\boldsymbol{x}</em>{t-1}},(1-\alpha_t))\boldsymbol{I})$，我们还需要得到：$q(\boldsymbol{x}<em>t\vert \boldsymbol{x}_0)$ 和$q(\boldsymbol{x}</em>{t-1}\vert \boldsymbol{x}<em>0)$的形式，使用重参数化技巧，样本 $\boldsymbol{x}_t\sim q(\boldsymbol{x}_t\vert \boldsymbol{x}</em>{t-1})$ ：</p> \[\boldsymbol{x}_t=\sqrt{\alpha_t}\boldsymbol{x}_{t-1}+\sqrt{1-\alpha_t}\boldsymbol{\epsilon}\quad\text{with}\quad\boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{x}_t;0,\boldsymbol{I})\] <p>类似的，可以递推到下一项：</p> \[\boldsymbol{x}_{t-1}=\sqrt{\alpha_{t-1}}\boldsymbol{x}_{t-2}+\sqrt{1-\alpha_{t-1}}\boldsymbol{\epsilon}\quad\mathrm{with}\quad\boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{x}_{t-1};\boldsymbol{0},\boldsymbol{I})\] <p>根据高斯分布的叠加方法：</p> \[\begin{aligned}\boldsymbol{x}_{t}&amp;=\sqrt{\alpha_{t}}\left(\sqrt{\alpha_{t-1}}\boldsymbol{x}_{t-2}+\sqrt{1-\alpha_{t-1}}\boldsymbol{\epsilon}_{t-1}\right)+\sqrt{1-\alpha}\boldsymbol{\epsilon}_{t}\\&amp;=\sqrt{\alpha_{t}\alpha_{t-1}}\boldsymbol{x}_{t-2}+\sqrt{1-\alpha_{t}\alpha_{t-1}}\boldsymbol{\epsilon}\quad \text{with}\quad \boldsymbol{\epsilon}\sim\mathcal{N}(\boldsymbol{x}_t;0,\boldsymbol(1-\alpha_t \alpha_{t-1}){I})\end{aligned}\] <p>以此类推，所有的$\boldsymbol{x}_t$都可以关联到$\boldsymbol{x}_0$</p> \[\begin{aligned}\boldsymbol{x}_{t}&amp;=\sqrt{\prod_{i=1}^{t}\alpha_{i}}\boldsymbol{x}_{0}+\sqrt{1-\prod_{i=1}^{t}\alpha_{i}}\epsilon\\&amp;=\sqrt{\bar{\alpha}_t}\boldsymbol{x}_0+\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon} \sim\mathcal{N}(\boldsymbol{x}_t;\sqrt{\bar{\alpha}_t}\boldsymbol{x}_0,(1-\bar{\alpha}_t)\boldsymbol{I})\end{aligned}\] <p>由此，对ELBO中的公式有：</p> \[\begin{aligned} &amp;q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0) \\ =&amp;\frac{q(\boldsymbol{x}_t\vert \boldsymbol{x}_{t-1},\boldsymbol{x}_0)q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_0)}{q(\boldsymbol{x}_t\vert \boldsymbol{x}_0)} \\ =&amp;\frac{\mathcal{N}(\boldsymbol{x}_t;\sqrt{\alpha_t}\boldsymbol{x}_{t-1},(1-\alpha_t)\boldsymbol{I})\mathcal{N}(\boldsymbol{x}_{t-1};\sqrt{\bar{\alpha}_{t-1}}\boldsymbol{x}_0,(1-\bar{\alpha}_{t-1})\boldsymbol{I})}{\mathcal{N}(\boldsymbol{x}_t;\sqrt{\bar{\alpha}_t}\boldsymbol{x}_0,(1-\bar{\alpha}_t)\boldsymbol{I})} \end{aligned}\] <p>可以将上面的式子转换成具体公式，进行进一步化简，将其中每一项展开为具体的高斯分布公式：</p> \[\begin{aligned} &amp;q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0) \\ \propto&amp;\exp\left\{-\left[\frac{(\boldsymbol{x}_t-\sqrt{\alpha_t}\boldsymbol{x}_{t-1})^2}{2(1-\alpha_t)}+\frac{(\boldsymbol{x}_{t-1}-\sqrt{\bar{\alpha}_{t-1}}\boldsymbol{x}_0)^2}{2(1-\bar{\alpha}_{t-1})}-\frac{(\boldsymbol{x}_t-\sqrt{\bar{\alpha}_t}\boldsymbol{x}_0)^2}{2(1-\bar{\alpha}_t)}\right]\right\} \end{aligned}\] <p>化简得到：</p> \[\mathcal{N}(\boldsymbol{x}_{t-1};\underbrace{\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})\boldsymbol{x}_t+\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)\boldsymbol{x}_0}{1-\bar{\alpha}_t}}_{\boldsymbol{\mu}_q(\boldsymbol{x}_t,\boldsymbol{x}_0)},\underbrace{\frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\boldsymbol{I}}_{\boldsymbol{\sigma}_q(t)})\] <p>上面的$\alpha$要么被视为超参数而设定，要么等待网络进行预测。更改记号将方差记作：</p> \[\boldsymbol{\Sigma}_q=\boldsymbol{\sigma}^2_q(t)\boldsymbol{I}=\frac{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}{1-\bar{\alpha}_t}\boldsymbol{I}\] <p>两个高斯分布之间的KL散度为：</p> \[\begin{aligned} &amp;D_{KL}(\mathcal{N}(\boldsymbol{x};\boldsymbol{\mu}_{\boldsymbol{x}},\boldsymbol{\Sigma}_{\boldsymbol{x}})\Vert \mathcal{N}(\boldsymbol{y};\boldsymbol{\mu}_{\boldsymbol{y}},\boldsymbol{\Sigma}_{\boldsymbol{y}})) \\ =&amp;\frac12{\left[\log\frac{\vert \boldsymbol{\Sigma}_y\vert }{\vert \boldsymbol{\Sigma}_x\vert }+tr(\boldsymbol{\Sigma}_y^{-1}\boldsymbol{\Sigma}_x)+(\boldsymbol{\mu}_y-\boldsymbol{\mu}_x)^\mathrm{T}\boldsymbol{\Sigma}_y^{-1}(\boldsymbol{\mu}_y-\boldsymbol{\mu}_x)-n\right]} \end{aligned}\] <p>其中$n$为$n$元高斯分布导致的结果，在我们研究的情况中，可以让两个高斯分布的方差精确匹配，因此，优化kL散度项即最小化两个分布的均值之差：</p> \[\begin{aligned} &amp;\arg\min_\theta D_{KL}(q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0)\parallel p_\theta(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t)) \\ &amp;=\arg\min_\theta\frac12{\left[\log\frac{\vert \boldsymbol{\Sigma}_\theta\vert }{\vert \boldsymbol{\Sigma}_q\vert }+tr(\boldsymbol{\Sigma}_\theta^{-1}\boldsymbol{\Sigma}_q)+(\boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q)^\mathrm{T}\boldsymbol{\Sigma}_\theta^{-1}(\boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q)-n\right]} \\ &amp;=\arg\min_\theta\frac12{\left[1+n+(\boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q)^\mathrm{T}\boldsymbol{\Sigma}_q^{-1}(\boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q)-n\right]} \\ &amp;=\arg\min_\theta\frac12{\left[(\boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q)^\mathrm{T}(\sigma_q^2(t)\boldsymbol{I})^{-1}(\mu_\theta-\mu_q)\right]} \\ &amp;=\arg\min_\theta\frac1{2\sigma_q^2(t)}{\left[\left\Vert \boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q\right\Vert _2^2\right]} \end{aligned}\] <p>其中 $\boldsymbol{\mu}_q(\boldsymbol{x}_t,\boldsymbol{x}_0)$ 在前面已经得到</p> \[\boldsymbol{\mu}_q(\boldsymbol{x}_t,\boldsymbol{x}_0)=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})\boldsymbol{x}_t+\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)\boldsymbol{x}_0}{1-\bar{\alpha}_t}\] <p>为进一步简化，将$\boldsymbol{\mu}_\theta(\boldsymbol{x}_t,t)$也写成类似的形式：</p> \[\boldsymbol{\mu}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)=\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})\boldsymbol{x}_t+\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)\hat{\boldsymbol{x}}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)}{1-\bar{\alpha}_t}\] <p>$\hat{\boldsymbol{x}}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)$由一个神经网络参数化：该网络用时间$t$，和噪声图像$\boldsymbol{x}_t$预测原始图像$\boldsymbol{x}_0$。由此，优化问题变为：</p> \[\begin{aligned} &amp;\arg\min_\theta D_{KL}(q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0)\parallel p_\theta(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t)) \\ =&amp;\arg\min_\theta\frac1{2\sigma_q^2(t)}{\left[\left\Vert \boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q\right\Vert _2^2\right]} \\ =&amp;\arg\min_\theta\frac1{2\boldsymbol{\sigma}_q^2(t)}{\left[\Vert \frac{\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)}{1-\bar{\alpha}_t}(\hat{\boldsymbol{x}}_\theta(\boldsymbol{x}_t,t)-\boldsymbol{x}_0)\Vert _2^2\right]} \\ =&amp;\arg\min_\theta\frac1{2\boldsymbol{\sigma}_q^2(t)}\frac{\bar{\alpha}_{t-1}(1-\alpha_t)^2}{(1-\bar{\alpha}_t)^2}\biggl[\Vert (\hat{\boldsymbol{x}}_\theta(\boldsymbol{x}_t,t)-\boldsymbol{x}_0)\Vert _2^2\biggr] \end{aligned}\] <h3 id="22-learning-diffusion-noise-parameters">2.2 Learning Diffusion Noise Parameters</h3> <p>我们前面提到，$\alpha$除了被设置为超参数建模，还可以通过神经网络建模，但如果将其设为$\alpha_\eta$来逐时间步建模，计算量极大，我们可以设计方法简化计算，将$\sigma_q$代入：</p> \[\begin{aligned} &amp;\frac{1}{2\boldsymbol{\sigma}_q^2(t)}\frac{\bar{\alpha}_{t-1}(1-\alpha_t)^2}{\left(1-\bar{\alpha}_t\right)^2}\left[\Vert (\hat{\boldsymbol{x}}_\theta(\boldsymbol{x}_t,t)-\boldsymbol{x}_0)\Vert _2^2\right] \\ =&amp;\frac12\frac{1-\bar{\alpha}_t}{(1-\alpha_t)(1-\bar{\alpha}_{t-1})}\frac{\bar{\alpha}_{t-1}(1-\alpha_t)^2}{(1-\bar{\alpha}_t)^2}\biggl[\Vert (\hat{\boldsymbol{x}}_\theta(\boldsymbol{x}_t,t)-\boldsymbol{x}_0)\Vert _2^2\biggr] \\ =&amp;\frac12\Bigg(\frac{\bar{\alpha}_{t-1}}{1-\bar{\alpha}_{t-1}}-\frac{\bar{\alpha}_t}{(1-\bar{\alpha}_t)}\Bigg)\Bigg[\Vert (\hat{\boldsymbol{x}}_\theta(\boldsymbol{x}_t,t)-\boldsymbol{x}_0)\Vert _2^2\Bigg] \end{aligned}\] <p>根据信噪比的定义我们有：</p> \[\mathrm{SNR}(t)=\frac{\bar{\alpha}_t}{1-\bar{\alpha}_t}\] <p>代入公式有：</p> \[\begin{aligned}&amp;\frac1{2\sigma_q^2(t)}\frac{\bar{\alpha}_{t-1}(1-\alpha_t)^2}{(1-\bar{\alpha}_t)^2}\Big[\left\Vert \hat{\boldsymbol{x}}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)-\boldsymbol{x}_0\right\Vert _2^2\Big]\\=&amp;\frac12(\mathrm{SNR}(t-1)-\mathrm{SNR}(t))\left[\left\Vert \hat{\boldsymbol{x}}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)-\boldsymbol{x}_0\right\Vert _2^2\right]\end{aligned}\] <p>可以使用神经网络在每个时间步上参数化SNR，与扩散模型进行联合学习，由于SNR随时间单调减小，可以表示为：</p> \[\mathrm{SNR}(t)=\exp(-\omega_\eta(t))\] <p>我们可以得到一组美丽的公式：</p> \[\begin{aligned} \frac{\bar{\alpha}_t}{1-\bar{\alpha}_t}&amp;=\exp(-\omega_\eta(t))\\\bar{\alpha}_t&amp;=\mathrm{sigmoid}(-\omega_\eta(t))\\1-\bar{\alpha}_t&amp;=\mathrm{sigmoid}(\omega_\eta(t)) \end{aligned}\] <h3 id="23-three-equivalent-interpretations">2.3 Three Equivalent Interpretations</h3> <p>$\boldsymbol{x}_{0}$ 还有两种参数化形式，导向另外两种解释：</p> <p>在重参数化递推的过程中，可以得到：</p> \[\boldsymbol{x}_0=\frac{\boldsymbol{x}_t-\sqrt{1-\bar{\alpha}_t}\boldsymbol{\epsilon}}{\sqrt{\bar{\alpha}_t}}\] <p>代入均值公式：</p> \[\begin{gathered} \boldsymbol{\mu}_q(\boldsymbol{x}_t,\boldsymbol{x}_0) =\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})\boldsymbol{x}_t+\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)\boldsymbol{x}_0}{1-\bar{\alpha}_t} \\ =\frac1{\sqrt{\alpha_t}}\boldsymbol{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\boldsymbol{\epsilon} \end{gathered}\] <p>将预测均值也转换成相应形式：</p> \[\boldsymbol{\mu}_\theta(\boldsymbol{x}_t,t)=\frac1{\sqrt{\alpha_t}}\boldsymbol{x}_t-\frac{1-\alpha_t}{\sqrt{1-\bar{\alpha}_t}\sqrt{\alpha_t}}\hat{\boldsymbol{\epsilon}}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)\] <p>相应的优化问题变为：</p> \[\begin{aligned} &amp;\arg\min_\theta D_{KL}(q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0)\parallel p_\theta(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t)) \\ =&amp;\arg\min_\theta\frac1{2\sigma_q^2(t)}{\left[\left\Vert \boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q\right\Vert _2^2\right]} \\ =&amp;\arg\min_\theta\frac1{2\sigma_q^2(t)}\frac{(1-\alpha_t)^2}{(1-\bar{\alpha}_t)\alpha_t}\Big[\left\Vert (\boldsymbol{\epsilon}-\hat{\boldsymbol{\epsilon}}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t))\right\Vert _2^2\Big] \end{aligned}\] <p>将学习预测目标从样本转向噪声，从而进一步得到样本，研究表明，这种方法训练结果优于直接得到样本。</p> <p>前面得到 $q(\boldsymbol{x}_t\vert \boldsymbol{x}_0)=\mathcal{N}(\boldsymbol{x}_t;\sqrt{\bar{\alpha}_t}\boldsymbol{x}_0,(1-\bar{\alpha}_t)\boldsymbol{I})$ ，根据高斯分布和Tweedie 公式的性质：</p> \[\mathbb{E}[\boldsymbol{\mu}_{\boldsymbol{x}_t}\vert \boldsymbol{x}_t]=\boldsymbol{x}_t+(1-\bar{\alpha}_t)\nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t)\] <p>因此我们可以将重参数化的式子写为：</p> \[\sqrt{\bar{\alpha}_t}\boldsymbol{x}_0=\boldsymbol{x}_t+(1-\bar{\alpha}_t)\nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t)\\\therefore\boldsymbol{x}_0=\frac{\boldsymbol{x}_t+(1-\bar{\alpha}_t)\nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t)}{\sqrt{\bar{\alpha}_t}}\] <p>再次代入均值公式可以得到：</p> \[\begin{aligned} \boldsymbol{\mu}_q(\boldsymbol{x}_t,\boldsymbol{x}_0) =&amp;\frac{\sqrt{\alpha_t}(1-\bar{\alpha}_{t-1})\boldsymbol{x}_t+\sqrt{\bar{\alpha}_{t-1}}(1-\alpha_t)\boldsymbol{x}_0}{1-\bar{\alpha}_t} \\ =&amp; \frac1{\sqrt{\alpha_t}}\boldsymbol{x}_t+\frac{1-\alpha_t}{\sqrt{\alpha_t}}\nabla\log p(\boldsymbol{x}_t) \end{aligned}\] <p>对应的去噪过程预测均值为：</p> \[\boldsymbol{\mu}_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)=\frac1{\sqrt{\alpha_t}}\boldsymbol{x}_t+\frac{1-\alpha_t}{\sqrt{\alpha_t}}s_{\boldsymbol{\theta}}(\boldsymbol{x}_t,t)\] <p>对应的优化问题：</p> \[\begin{aligned} &amp;\arg\min_\theta D_{KL}(q(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t,\boldsymbol{x}_0)\parallel p_\theta(\boldsymbol{x}_{t-1}\vert \boldsymbol{x}_t)) \\ =&amp;\arg\min_\theta\frac1{2\sigma_q^2(t)}{\left[\left\Vert \boldsymbol{\mu}_\theta-\boldsymbol{\mu}_q\right\Vert _2^2\right]} \\ =&amp;\arg\min_{\boldsymbol{\theta}}\frac{1}{2\sigma_{q}^{2}(t)}\frac{(1-\alpha_{t})^{2}}{\alpha_{t}}\Big[\left\Vert s_{\boldsymbol{\theta}}(\boldsymbol{x}_{t},t)-\nabla\log p(\boldsymbol{x}_{t})\right\Vert _{2}^{2}\Big] \end{aligned}\] <p>对比上面的过程，得到得分与噪声之间的关联：</p> \[\nabla_{\boldsymbol{x}_t}\log p(\boldsymbol{x}_t)=-\frac1{\sqrt{1-\bar{\alpha}_t}}\boldsymbol{\epsilon}_0\] <p>两者之间相差一个随时间变化的常数，得分函数测量了数据流行上如何移动最大化对数概率；由于源噪声被添加，因此反方向会去噪声，从上面的公式可以看出，得分与噪声的相反数之间相差一个正的常数。</p> <p>我们在数学上（并非在计算机实现上）得出了三个等效的优化目标：原始图像，原始噪声，或得分函数。通过随机采样时间步长并使预测结果与真实结果范数最小化，可以进行训练。</p> <h2 id="3-score-based-generative-models">3 Score-based Generative Models</h2> <p>我们得到得分函数只是根据一个数学技巧，目前还没有展示出更深层次的内涵，但出于其与物理学之间的深刻关联，我们相信其有值得思考的内容，对比基于能量的模型：</p> \[p_\theta(\boldsymbol{x})=\frac1{z_\theta}e^{-f_\theta(\boldsymbol{x})}\] <p>但是公式中涉及配分函数，虽然配分函数可以带来很多工具和很好的性质，但是配分函数本身的计算是困难的，对上面的式子取对数后求导得到：</p> \[\begin{aligned} \nabla_{\boldsymbol{x}}\log p_{\boldsymbol{\theta}}(\boldsymbol{x})&amp; =\nabla_{\boldsymbol{x}}\log(\frac1{\boldsymbol{z_\theta}}e^{-f_{\boldsymbol{\theta}}(\boldsymbol{x})}) \\ &amp;=\nabla_x\log\frac1{z_\theta}+\nabla_x\log e^{-f_\theta(\boldsymbol{x})} \\ &amp;=-\nabla_xf_\theta(\boldsymbol{x}) \\ &amp;\approx s_\theta(\boldsymbol{x}) \end{aligned}\] <p>可以很容易被表示为神经网络，并且不需要计算配分函数。很容易想到的一个优化方法：</p> \[\mathbb{E}_{p(\boldsymbol{x})}\left[\left\Vert s_{\boldsymbol{\theta}}(\boldsymbol{x})-\nabla\log p(\boldsymbol{x})\right\Vert _2^2\right]\] <p>我们现在可以思考得分函数的意义，对于每个$\boldsymbol{x}$，取对数似然的梯度，描述了要增加似然度所移动的方向。因此得分函数在整个空间上定义了一个模式（fiber bundle？）的向量场。学习真实系统的得分函数，可以从任意一点开始，通过迭代跟随得分函数，进行演化，直到到达具体的模式，即生成样本，这个采样过程是Langevin动力学：</p> \[\boldsymbol{x}_{i+1}=\boldsymbol{x}_i+c\nabla\log p(\boldsymbol{x}_i)+\sqrt{2c}\boldsymbol{\epsilon},\quad i=0,1,\ldots,K\] <p>其中$\boldsymbol{x}_0$是从先验分布采样得到，$\boldsymbol{\epsilon}$是额外的噪声项，确保生成结果不总是塌陷到一个模式上，确保结果的多样性。并且，得分函数是确定的，噪声可以使生成过程随机性增强。</p> <p>上面的目标函数依赖真实的得分函数，对于模拟复杂图像分布等复杂情况而言，真实得分无法得到。但我们可以使用得分匹配技术作为替代方案，在不知道得分的情况下最小化Fisher散度，并使用随机梯度下降优化。</p> <p>通过得分函数学习分布，并使用Langevin动力学生成样本，被称为基于得分的生成模型。得分匹配的三个问题主要是：</p> <p>首先，出于高维空间中的低维流形时，得分函数未定义，在数学上，不在低维流形上概率为0，对数无定义。这在尝试学习自然图像的生成建模时很困难。</p> <p>其次，通过普通得分匹配训练的估计得分函数在低密度区不准确，它是对$p$的期望，并且在其样本上进行训练，模型在未见或少见样本上无法准确学习信号。我们的采样策略涉及从高维空间的随机位置开始，这个位置很可能是随机噪声，并且根据学习的得分函数进行移动。如果遵循不准确的得分估计，最终生成的样本也不够优化，或者需要经过更多的迭代，才能得到结果。</p> <p>最后，即使使用真实的得分进行Langevin动力学采样，也可能无法混合。假设真实分布是不想交的分布的混合：</p> \[p(\boldsymbol{x})=c_1p_1(\boldsymbol x)+c_2p_2(\boldsymbol x)\] <p>在计算得分时，这些混合系数会丢失，因为对数运算将系数从分布中分离出来，并在经过梯度计算后变为0。</p> <p>可以通过向数据添加多层高斯噪声来同时解决这三个缺点。</p> <p>首先高斯噪声分布支持整个空间，扰动后的数据不再限于低维流形上。</p> <p>其次，大量的高斯噪声会增加每个模式在数据分布的覆盖范围，在低密度区增加更多的训练信号。</p> <p>最后，通过添加方差递增的多层高斯噪声，可以得到对应于真实混合系数的中间分布。</p> <p>形式上，可以选择一个噪声水平为${\sigma_t}_{t=1}^T$的正序列，并定义一个渐进扰动数据分布序列：</p> \[p_{\boldsymbol{\sigma}_t}(\boldsymbol{x}_t)=\int p(\boldsymbol{x})\mathcal{N}(\boldsymbol{x}_t;\boldsymbol{x},\boldsymbol{\sigma}_t^2\boldsymbol{I})dx\] <p>然后，使用得分匹配学习神经网络$s_{\theta}(\boldsymbol{x},t)$ ，以同时学习所有噪声水平的得分函数：</p> \[\arg\min_{\boldsymbol{\theta}}\sum_{t=1}^T\lambda(t)\mathbb{E}_{p_{\boldsymbol{\sigma}_t}(\boldsymbol{x})}\left\lfloor\left\Vert s_{\boldsymbol{\theta}}(\boldsymbol{x})-\nabla\log p_{\boldsymbol{\sigma}_t}(\boldsymbol{x})\right\Vert _2^2\right\rfloor\] <p>其中，$\lambda(t)$ 为对噪声水平添加条件的正权重函数。这个目标与VDM训练公式推导出的目标相匹配。</p> <p>此外，可以使用退火Langevin动力学采样生成，样本是按顺序在每个$t=T,T-1,\cdots,2,1$上运行朗之万动力学来生成的。初始化是从某固定先验中选择的，并且后续的采样都从前一个仿真的最终样本开始。由于随时间步长减小，噪声水平下降，我们逐渐减小步长，样本会逐渐收敛到真实的模式下，这也和VDM采样过程有所关联。在训练目标和采样过程上VDM和基于得分的模型之间都有明确的联系。</p> <p>一个很自然的想法，是研究理想情况下，也就是无限数量的时间步骤情况下的情况，在VDM视角下，可以视为将层数扩展到无穷大，从基于得分的观点看可以使用随机过程方法，用随机微分方程（SDE）来描述。采样通过求解反向SDE进行，自然要求在每个连续值的噪声水平估计得分。SDE不同参数表示随时间的不同扰动，可以实现对噪声的灵活建模。</p> <h2 id="4-guidence">4 Guidence</h2> <p>到目前为止，只研究了数据本身的分布$p(\boldsymbol{x})$，但在很多场景下，需要条件分布$p(\boldsymbol{x}|y)$我们可以通过条件信息$y$来控制数据生成，一种很自然的想法是将条件信息和每个时间步的信息一起添加：</p> \[p(\boldsymbol{x}_{0:T})=p(\boldsymbol{x}_T)\prod_{t=1}^Tp_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t)\] <p>很自然，我们可以得到：</p> \[p(\boldsymbol{x}_{0:T}|y)=p(\boldsymbol{x}_T)\prod_{t=1}^Tp_{\boldsymbol{\theta}}(\boldsymbol{x}_{t-1}|\boldsymbol{x}_t,y)\] <table> <tbody> <tr> <td>例如，图像-文本问题上，$y$可以是文本编码等，因此可以通过 $\hat{\boldsymbol{x}}<em>\theta(\boldsymbol{x}_t,t,y)\approx\boldsymbol{x}_0, \hat{\boldsymbol{\epsilon}}</em>\theta(\boldsymbol{x}<em>t,t,y)\approx\boldsymbol{\epsilon}_0$ 或者 $s</em>\theta(\boldsymbol{x}_t,t,y)\approx\nabla\log p(\boldsymbol{x}_t</td> <td>y)$ 的每个所需解释和实现，来学习VDM的核心神经网络。</td> </tr> </tbody> </table> <p>但过程中需要注意，这种方法训练的模型可能会忽略或淡化给定条件，但如果更明确控制模型赋予条件信息权重，会导致生成样本多样性减少。目前常用的是分类器指导和无分类器指导两种形式。</p> <h3 id="41-classifier-guidance">4.1 Classifier Guidance</h3> <table> <tbody> <tr> <td>基于得分的模型目标是学习任意噪声水平$t$下的得分函数：$\nabla\log p(\boldsymbol{x}_t</td> <td>y)$，很自然的根据贝叶斯法则：</td> </tr> </tbody> </table> \[\begin{aligned} \nabla\log p(\boldsymbol{x}_t|y)&amp; =\nabla\log\left(\frac{p(\boldsymbol{x}_t)p(y|\boldsymbol{x}_t)}{p(y)}\right) \\ &amp;=\nabla\log p(\boldsymbol{x}_t)+\nabla\log p(y|\boldsymbol{x}_t)-\nabla\log p(y) \\ &amp;=\underbrace{\nabla\log p(\boldsymbol{x}_t)}_{\text{无条件得分}}+\underbrace{\nabla\log p(y|\boldsymbol{x}_t)}_{\text{对抗梯度}} \end{aligned}\] <p>因此，分类器指导的方法，需要先学习一个无分类器的扩散模型得分，之后再学习分类器，这个分类器接受任意噪声输入$\boldsymbol{x}_{t}$，并预测条件信息$y$。采样过程中用于退火Langevin动力学的整体条件得分函数被计算为无条件得分函数和噪声分类器的对抗梯度之和。为了引入细粒化控制，用来鼓励或者阻止模型考虑条件信息，引入超参数$\gamma$用以调节噪声分类器的对抗梯度。</p> \[\nabla\log p(\boldsymbol{x}_t|y)=\nabla\log p(\boldsymbol{x}_t)+\gamma\nabla\log p(y|\boldsymbol{x}_t)\] <p>可以通过超参数调节生成模型的条件重要性和样本多样性，分类器指导的显著问题是依赖单独学习的分类器，由于分类器必须处理任意噪声输入，而大多数现有的预训练分类模型不针对这个问题进行优化，因此需要和扩散模型同时进行专门学习。</p> <h3 id="42-classifier-free-guidance">4.2 Classifier-Free Guidance</h3> <p>无分类器指导的模型，不需要训练一个单独的分类器模型，使用无条件扩散和条件扩散。重新组合之前的公式：</p> \[\nabla\log p(y|\boldsymbol{x}_t)=\nabla\log p(\boldsymbol{x}_t|y)-\nabla\log p(\boldsymbol{x}_t)\] <p>再代入存在超参数的公式：</p> \[\begin{gathered} \nabla\log p(\boldsymbol{x}_t|y) =\nabla\log p(\boldsymbol{x}_t)+\gamma(\nabla\log p(\boldsymbol{x}_t|y)-\nabla\log p(\boldsymbol{x}_t)) \\ =\underbrace{\gamma\nabla\log p(\boldsymbol{x}_t|y)}_{\text{条件得分}}+\underbrace{(1-\gamma)\nabla\log p(\boldsymbol{x}_t)}_{\text{无条件得分}} \end{gathered}\] <p>$\gamma$是控制学习到的模型对条件信息关注程度的参数，$\gamma=0$时完全忽略条件，$\gamma=1$时模型学习无指导的基本条件分布，$\gamma&gt;1$时，扩散模型不仅有限考虑条件得分函数，还朝着远离无条件得分函数的方向移动，即减小生成无条件信息的样本的概率。</p> <p>由于同时学习两个模型成本较高，因此可以将条件模型和无条件模型一起作为一个单独的条件模型学习，无条件信息可以将条件信息固定为固定常数，例如0来学习。这本质上是对条件信息执行随机丢弃</p> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Li Fancheng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-notes",title:"Notes",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"Publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-repositories",title:"Repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/repositories/"}},{id:"nav-cv",title:"CV",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"post-\u6269\u6563\u6a21\u578b\u521d\u6b65",title:"\u6269\u6563\u6a21\u578b\u521d\u6b65",description:"\u6269\u6563\u6a21\u578b\u5165\u95e8\uff0c\u5305\u62ecDDPM\u548cSLDM",section:"Posts",handler:()=>{window.location.href="/blog/2024/%E6%89%A9%E6%95%A3%E6%A8%A1%E5%9E%8B%E5%88%9D%E6%AD%A5/"}},{id:"post-google-gemini-updates-flash-1-5-gemma-2-and-project-astra",title:'Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"We\u2019re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.",section:"Posts",handler:()=>{window.open("https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/","_blank")}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/tabs/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/blog/2024/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/blog/2024/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2024/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/blog/2023/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/blog/2023/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/blog/2023/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/blog/2023/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/blog/2023/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/blog/2023/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/blog/2023/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/blog/2022/giscus-comments/"}},{id:"post-displaying-external-posts-on-your-al-folio-blog",title:'Displaying External Posts on Your al-folio Blog <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2","_blank")}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/blog/2021/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/blog/2021/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/blog/2020/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/blog/2015/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/blog/2015/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/blog/2015/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/blog/2015/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/blog/2015/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>